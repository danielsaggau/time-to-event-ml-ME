
@article{kamarudin_time-dependent_2017,
	title = {Time-dependent {ROC} curve analysis in medical research: current methods and applications},
	volume = {17},
	issn = {1471-2288},
	shorttitle = {Time-dependent {ROC} curve analysis in medical research},
	url = {http://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-017-0332-6},
	doi = {10.1186/s12874-017-0332-6},
	abstract = {Background: ROC (receiver operating characteristic) curve analysis is well established for assessing how well a marker is capable of discriminating between individuals who experience disease onset and individuals who do not. The classical (standard) approach of ROC curve analysis considers event (disease) status and marker value for an individual as fixed over time, however in practice, both the disease status and marker value change over time. Individuals who are disease-free earlier may develop the disease later due to longer study follow-up, and also their marker value may change from baseline during follow-up. Thus, an ROC curve as a function of time is more appropriate. However, many researchers still use the standard ROC curve approach to determine the marker capability ignoring the time dependency of the disease status or the marker.
Methods: We comprehensively review currently proposed methodologies of time-dependent ROC curves which use single or longitudinal marker measurements, aiming to provide clarity in each methodology, identify software tools to carry out such analysis in practice and illustrate several applications of the methodology. We have also extended some methods to incorporate a longitudinal marker and illustrated the methodologies using a sequential dataset from the Mayo Clinic trial in primary biliary cirrhosis (PBC) of the liver.
Results: From our methodological review, we have identified 18 estimation methods of time-dependent ROC curve analyses for censored event times and three other methods can only deal with non-censored event times. Despite the considerable numbers of estimation methods, applications of the methodology in clinical studies are still lacking.
Conclusions: The value of time-dependent ROC curve methods has been re-established. We have illustrated the methods in practice using currently available software and made some recommendations for future research.},
	language = {en},
	number = {1},
	urldate = {2020-11-28},
	journal = {BMC Medical Research Methodology},
	author = {Kamarudin, Adina Najwa and Cox, Trevor and Kolamunnage-Dona, Ruwanthi},
	month = dec,
	year = {2017},
	pages = {53},
	file = {Kamarudin et al. - 2017 - Time-dependent ROC curve analysis in medical resea.pdf:files/1912/Kamarudin et al. - 2017 - Time-dependent ROC curve analysis in medical resea.pdf:application/pdf}
}

@article{cook_statistical_2008,
	title = {Statistical {Evaluation} of {Prognostic} versus {Diagnostic} {Models}: {Beyond} the {ROC} {Curve}},
	volume = {54},
	issn = {0009-9147, 1530-8561},
	shorttitle = {Statistical {Evaluation} of {Prognostic} versus {Diagnostic} {Models}},
	url = {https://academic.oup.com/clinchem/article/54/1/17/5628417},
	doi = {10.1373/clinchem.2007.096529},
	abstract = {Although it is useful for classification, evaluation of prognostic models should not rely solely on the ROC curve, but should assess both discrimination and calibration. Risk reclassification can aid in comparing the clinical impact of two models on risk for the individual, as well as the population.},
	language = {en},
	number = {1},
	urldate = {2020-11-28},
	journal = {Clinical Chemistry},
	author = {Cook, Nancy R},
	month = jan,
	year = {2008},
	pages = {17--23},
	file = {Cook - 2008 - Statistical Evaluation of Prognostic versus Diagno.pdf:files/1913/Cook - 2008 - Statistical Evaluation of Prognostic versus Diagno.pdf:application/pdf}
}

@article{gerds_performance_2008,
	title = {The {Performance} of {Risk} {Prediction} {Models}},
	volume = {50},
	issn = {03233847, 15214036},
	url = {http://doi.wiley.com/10.1002/bimj.200810443},
	doi = {10.1002/bimj.200810443},
	abstract = {For medical decision making and patient information, predictions of future status variables play an important role. Risk prediction models can be derived with many different statistical approaches. To compare them, measures of predictive performance are derived from ROC methodology and from probability forecasting theory. These tools can be applied to assess single markers, multivariable regression models and complex model selection algorithms. This article provides a systematic review of the modern way of assessing risk prediction models. Particular attention is put on proper benchmarks and resampling techniques that are important for the interpretation of measured performance. All methods are illustrated with data from a clinical study in head and neck cancer patients.},
	language = {en},
	number = {4},
	urldate = {2020-11-28},
	journal = {Biometrical Journal},
	author = {Gerds, Thomas A. and Cai, Tianxi and Schumacher, Martin},
	month = aug,
	year = {2008},
	pages = {457--479},
	file = {Gerds et al. - 2008 - The Performance of Risk Prediction Models.pdf:files/1916/Gerds et al. - 2008 - The Performance of Risk Prediction Models.pdf:application/pdf}
}

@article{heagerty_time-dependent_2000,
	title = {Time-{Dependent} {ROC} {Curves} for {Censored} {Survival} {Data} and a {Diagnostic} {Marker}},
	volume = {56},
	issn = {0006341X},
	url = {http://doi.wiley.com/10.1111/j.0006-341X.2000.00337.x},
	doi = {10.1111/j.0006-341X.2000.00337.x},
	abstract = {R. OC curves are a popular method for displaying sensitivity and specificity of a continuous diagnostic marker, X , for a binary disease variable, D . However, many disease outcomes are time dependent, D ( t ) , and ROC curves that vary as a function of time may be more appropriate. A common example of a time-dependent variable is vital status, where D ( t ) = 1 if a patient has died prior t o time t and zero otherwise. We propose summarizing the discrimination potential of a marker X , measured at baseline ( t = O ) , by calculating ROC curves for cumulative disease or death incidence by time t , which we denote as ROC(t). A typical complexity with survival data is that observations may be censored. Two ROC curve estimators are proposed that can accommodate censored data. A simple estimator is based on using the Kaplan-Meier estimator for each possible subset X {\textgreater} c. However, this estimator does not guarantee the necessary condition that sensitivity and specificity are monotone in X . An alternative estimator that does guarantee monotonicity is based on a nearest neighbor estimator for the bivariate distribution function of ( X ,T ) ,where T represents survival time (Akritas, M. J., 1994, Annuls of Statistics 22, 1299-1327). We present an example where ROC(t) is used t o compare a standard and a modified flow cytometry measurement for predicting survival after detection of breast cancer and an example where the ROC(t) curve displays the impact of modifying eligibility criteria for sample size and power in HIV prevention trials.},
	language = {en},
	number = {2},
	urldate = {2020-11-28},
	journal = {Biometrics},
	author = {Heagerty, Patrick J. and Lumley, Thomas and Pepe, Margaret S.},
	month = jun,
	year = {2000},
	pages = {337--344},
	file = {Heagerty et al. - 2000 - Time-Dependent ROC Curves for Censored Survival Da.pdf:files/1917/Heagerty et al. - 2000 - Time-Dependent ROC Curves for Censored Survival Da.pdf:application/pdf}
}

@article{kattan_index_2018,
	title = {The index of prediction accuracy: an intuitive measure useful for evaluating risk prediction models},
	volume = {2},
	issn = {2397-7523},
	shorttitle = {The index of prediction accuracy},
	url = {https://diagnprognres.biomedcentral.com/articles/10.1186/s41512-018-0029-2},
	doi = {10.1186/s41512-018-0029-2},
	abstract = {Background: Many measures of prediction accuracy have been developed. However, the most popular ones in typical medical outcome prediction settings require additional investigation of calibration.
Methods: We show how rescaling the Brier score produces a measure that combines discrimination and calibration in one value and improves interpretability by adjusting for a benchmark model. We have called this measure the index of prediction accuracy (IPA). The IPA permits a common interpretation across binary, time to event, and competing risk outcomes. We illustrate this measure using example datasets.
Results: The IPA is simple to compute, and example code is provided. The values of the IPA appear very interpretable.
Conclusions: IPA should be a prominent measure reported in studies of medical prediction model performance. However, IPA is only a measure of average performance and, by default, does not measure the utility of a medical decision.},
	language = {en},
	number = {1},
	urldate = {2020-11-28},
	journal = {Diagnostic and Prognostic Research},
	author = {Kattan, Michael W. and Gerds, Thomas A.},
	month = dec,
	year = {2018},
	pages = {7},
	file = {Kattan and Gerds - 2018 - The index of prediction accuracy an intuitive mea.pdf:files/1921/Kattan and Gerds - 2018 - The index of prediction accuracy an intuitive mea.pdf:application/pdf}
}

@article{cook_use_2007,
	title = {Use and {Misuse} of the {Receiver} {Operating} {Characteristic} {Curve} in {Risk} {Prediction}},
	volume = {115},
	issn = {0009-7322, 1524-4539},
	url = {https://www.ahajournals.org/doi/10.1161/CIRCULATIONAHA.106.672402},
	doi = {10.1161/CIRCULATIONAHA.106.672402},
	language = {en},
	number = {7},
	urldate = {2020-11-28},
	journal = {Circulation},
	author = {Cook, Nancy R.},
	month = feb,
	year = {2007},
	pages = {928--935},
	file = {Cook - 2007 - Use and Misuse of the Receiver Operating Character.pdf:files/1924/Cook - 2007 - Use and Misuse of the Receiver Operating Character.pdf:application/pdf}
}

@article{cook_use_2010,
	title = {The {Use} and {Magnitude} of {Reclassification} {Measures} for {Individual} {Predictors} of {Global} {Cardiovascular} {Risk}},
	abstract = {Models for risk prediction are widely used in clinical practice to risk stratify and assign treatment strategies. The contribution of new biomarkers has largely been based on the area under the receiver operating characteristic curve, but this measure can be insensitive to important changes in absolute risk. Methods based on risk stratification have recently been proposed to compare predictive models. These include the reclassification calibration statistic, the net reclassification improvement (NRI), and the integrated discrimination improvement (IDI). This work demonstrates the use of reclassification measures, and illustrates their performance for well-known cardiovascular risk predictors in a cohort of women. These measures are targeted at evaluating the potential of new models and markers to change risk strata and alter treatment decisions.},
	language = {en},
	author = {Cook, Nancy R and Ridker, Paul M},
	year = {2010},
	pages = {13},
	file = {Cook and Ridker - 2010 - The Use and Magnitude of Reclassification Measures.pdf:files/1927/Cook and Ridker - 2010 - The Use and Magnitude of Reclassification Measures.pdf:application/pdf}
}

@article{steyerberg_assessing_2010,
	title = {Assessing the {Performance} of {Prediction} {Models}: {A} {Framework} for {Traditional} and {Novel} {Measures}},
	volume = {21},
	issn = {1044-3983},
	shorttitle = {Assessing the {Performance} of {Prediction} {Models}},
	url = {http://journals.lww.com/00001648-201001000-00022},
	doi = {10.1097/EDE.0b013e3181c30fb2},
	abstract = {The performance of prediction models can be assessed using a variety of different methods and metrics. Traditional measures for binary and survival outcomes include the Brier score to indicate overall model performance, the concordance (or c) statistic for discriminative ability (or area under the receiver operating characteristic (ROC) curve), and goodness-of-fit statistics for calibration.},
	language = {en},
	number = {1},
	urldate = {2020-11-28},
	journal = {Epidemiology},
	author = {Steyerberg, Ewout W. and Vickers, Andrew J. and Cook, Nancy R. and Gerds, Thomas and Gonen, Mithat and Obuchowski, Nancy and Pencina, Michael J. and Kattan, Michael W.},
	month = jan,
	year = {2010},
	pages = {128--138},
	file = {Steyerberg et al. - 2010 - Assessing the Performance of Prediction Models A .pdf:files/1928/Steyerberg et al. - 2010 - Assessing the Performance of Prediction Models A .pdf:application/pdf}
}

@article{pencina_evaluating_2008,
	title = {Evaluating the added predictive ability of a new marker: {From} area under the {ROC} curve to reclassification and beyond},
	volume = {27},
	issn = {02776715, 10970258},
	shorttitle = {Evaluating the added predictive ability of a new marker},
	url = {http://doi.wiley.com/10.1002/sim.2929},
	doi = {10.1002/sim.2929},
	abstract = {Identiﬁcation of key factors associated with the risk of developing cardiovascular disease and quantiﬁcation of this risk using multivariable prediction algorithms are among the major advances made in preventive cardiology and cardiovascular epidemiology in the 20th century. The ongoing discovery of new risk markers by scientists presents opportunities and challenges for statisticians and clinicians to evaluate these biomarkers and to develop new risk formulations that incorporate them. One of the key questions is how best to assess and quantify the improvement in risk prediction offered by these new models. Demonstration of a statistically signiﬁcant association of a new biomarker with cardiovascular risk is not enough. Some researchers have advanced that the improvement in the area under the receiver-operating-characteristic curve (AUC) should be the main criterion, whereas others argue that better measures of performance of prediction models are needed. In this paper, we address this question by introducing two new measures, one based on integrated sensitivity and speciﬁcity and the other on reclassiﬁcation tables. These new measures offer incremental information over the AUC. We discuss the properties of these new measures and contrast them with the AUC. We also develop simple asymptotic tests of signiﬁcance. We illustrate the use of these measures with an example from the Framingham Heart Study. We propose that scientists consider these types of measures in addition to the AUC when assessing the performance of newer biomarkers. Copyright q 2007 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {2},
	urldate = {2020-11-28},
	journal = {Statistics in Medicine},
	author = {Pencina, Michael J. and D' Agostino, Ralph B. and D' Agostino, Ralph B. and Vasan, Ramachandran S.},
	month = jan,
	year = {2008},
	pages = {157--172},
	file = {Pencina et al. - 2008 - Evaluating the added predictive ability of a new m.pdf:files/1932/Pencina et al. - 2008 - Evaluating the added predictive ability of a new m.pdf:application/pdf}
}

@article{uno_c-statistics_2011,
	title = {On the {C}-statistics for evaluating overall adequacy of risk prediction procedures with censored survival data},
	volume = {30},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.4154},
	doi = {10.1002/sim.4154},
	abstract = {For modern evidence-based medicine, a well thought-out risk scoring system for predicting the occurrence of a clinical event plays an important role in selecting prevention and treatment strategies. Such an index system is often established based on the subject’s “baseline” genetic or clinical markers via a working parametric or semi-parametric model. To evaluate the adequacy of such a system, C-statistics are routinely used in the medical literature to quantify the capacity of the estimated risk score in discriminating among subjects with different event times. The Cstatistic provides a global assessment of a fitted survival model for the continuous event time rather than focuses on the prediction of t-year survival for a fixed time. When the event time is possibly censored, however, the population parameters corresponding to the commonly used Cstatistics may depend on the study-specific censoring distribution. In this article, we present a simple C-statistic without this shortcoming. The new procedure consistently estimates a conventional concordance measure which is free of censoring. We provide a large sample approximation to the distribution of this estimator for making inferences about the concordance measure. Results from numerical studies suggest that the new procedure performs well in finite sample.},
	language = {en},
	number = {10},
	urldate = {2020-11-28},
	journal = {Statistics in Medicine},
	author = {Uno, Hajime and Cai, Tianxi and Pencina, Michael J. and D'Agostino, Ralph B. and Wei, L. J.},
	month = may,
	year = {2011},
	pages = {1105--1117},
	file = {Uno et al. - 2011 - On the C-statistics for evaluating overall adequac.pdf:files/1935/Uno et al. - 2011 - On the C-statistics for evaluating overall adequac.pdf:application/pdf}
}

@article{vickers_decision_2006,
	title = {Decision {Curve} {Analysis}: {A} {Novel} {Method} for {Evaluating} {Prediction} {Models}},
	volume = {26},
	issn = {0272-989X, 1552-681X},
	shorttitle = {Decision {Curve} {Analysis}},
	url = {http://journals.sagepub.com/doi/10.1177/0272989X06295361},
	doi = {10.1177/0272989X06295361},
	abstract = {Background—Diagnostic and prognostic models are typically evaluated with measures of accuracy that do not address clinical consequences. Decision-analytic techniques allow assessment of clinical outcomes, but often require collection of additional information, and may be cumbersome to apply to models that yield a continuous result. We sought a method for evaluating and comparing prediction models that incorporates clinical consequences, requires only the dataset on which the models are tested, and can be applied to models that have either continuous or dichotomous results.
Method—We describe decision curve analysis, a simple, novel method of evaluating predictive models. We start by assuming that the threshold probability of a disease or event at which a patient would opt for treatment is informative of how the patient weighs the relative harms of a false-positive and a false-negative prediction. This theoretical relationship is then used to derive the net benefit of the model across different threshold probabilities. Plotting net benefit against threshold probability yields the “decision curve”. We apply the method to models for the prediction of seminal vesicle invasion in prostate cancer patients. Decision curve analysis identified the range of threshold probabilities in which a model was of value, the magnitude of benefit, and which of several models was optimal.
Conclusion—Decision curve analysis is a suitable method for evaluating alternative diagnostic and prognostic strategies that has advantages over other commonly used measures and techniques.},
	language = {en},
	number = {6},
	urldate = {2020-11-28},
	journal = {Medical Decision Making},
	author = {Vickers, Andrew J. and Elkin, Elena B.},
	month = nov,
	year = {2006},
	pages = {565--574},
	file = {Vickers and Elkin - 2006 - Decision Curve Analysis A Novel Method for Evalua.pdf:files/1936/Vickers and Elkin - 2006 - Decision Curve Analysis A Novel Method for Evalua.pdf:application/pdf}
}

@article{vickers_net_2016,
	title = {Net benefit approaches to the evaluation of prediction models, molecular markers, and diagnostic tests},
	issn = {1756-1833},
	url = {https://www.bmj.com/lookup/doi/10.1136/bmj.i6},
	doi = {10.1136/bmj.i6},
	language = {en},
	urldate = {2020-11-28},
	journal = {BMJ},
	author = {Vickers, Andrew J and Van Calster, Ben and Steyerberg, Ewout W},
	month = jan,
	year = {2016},
	pages = {i6},
	file = {Vickers et al. - 2016 - Net benefit approaches to the evaluation of predic.pdf:files/1937/Vickers et al. - 2016 - Net benefit approaches to the evaluation of predic.pdf:application/pdf}
}

@article{antolini_time-dependent_2005,
	title = {A time-dependent discrimination index for survival data},
	volume = {24},
	issn = {0277-6715, 1097-0258},
	url = {http://doi.wiley.com/10.1002/sim.2427},
	doi = {10.1002/sim.2427},
	abstract = {To derive models suitable for outcome prediction, a crucial aspect is the availability of appropriate measures of predictive accuracy, which have to be usable for a general class of models. The Harrell’s C discrimination index is an extension of the area under the ROC curve to the case of censored survival data, which owns a straightforward interpretability. For a model including covariates with time-dependent e ects and=or time-dependent covariates, the original deÿnition of C would require the prediction of individual failure times, which is not generally addressed in most clinical applications. Here we propose a time-dependent discrimination index C td where the whole predicted survival function is utilized as outcome prediction, and the ability to discriminate among subjects having di erent outcome is summarized over time. C td is based on a novel deÿnition of concordance: a subject who developed the event should have a less predicted probability of surviving beyond his=her survival time than any subject who survived longer. The predicted survival function of a subject who developed the event is compared to: (1) that of subjects who developed the event before his=her survival time, and (2) that of subjects who developed the event, or were censored, after his=her survival time. Subjects who were censored are involved in comparisons with subjects who developed the event before their observed times. The index reduces to the previous C in the presence of separation between survival curves on the whole follow-up. A conÿdence interval for C td is derived using the jackknife method on correlated one-sample U -statistics.},
	language = {en},
	number = {24},
	urldate = {2020-11-28},
	journal = {Statistics in Medicine},
	author = {Antolini, Laura and Boracchi, Patrizia and Biganzoli, Elia},
	month = dec,
	year = {2005},
	pages = {3927--3944},
	file = {Antolini et al. - 2005 - A time-dependent discrimination index for survival.pdf:files/1950/Antolini et al. - 2005 - A time-dependent discrimination index for survival.pdf:application/pdf}
}

@misc{lmu_munich_introduction_2020,
	title = {Introduction to {Machine} {Learning} · {A} {Free} {Interactive} {Course}},
	url = {https://introduction-to-machine-learning.netlify.app/},
	abstract = {The course is organized as a digital lecture, which should be as self-contained and enable self-study as much as possible. The major part of the material is provided as slide sets with lecture videos. We have also prepared interactive tutorials where you can answer multiple choice questions, and learn how to apply the covered methods in R on some short coding exercises. Our plan is to extend this self-study material over the next months and years.},
	language = {en},
	urldate = {2020-12-14},
	journal = {Introduction to Machine Learning},
	author = {LMU Munich},
	year = {2020},
	note = {Library Catalog: introduction-to-machine-learning.netlify.app},
	file = {Snapshot:files/2503/introduction-to-machine-learning.netlify.app.html:text/html}
}

@article{assel_brier_2017,
	title = {The {Brier} score does not evaluate the clinical utility of diagnostic tests or prediction models},
	volume = {1},
	issn = {2397-7523},
	url = {https://doi.org/10.1186/s41512-017-0020-3},
	doi = {10.1186/s41512-017-0020-3},
	abstract = {A variety of statistics have been proposed as tools to help investigators assess the value of diagnostic tests or prediction models. The Brier score has been recommended on the grounds that it is a proper scoring rule that is affected by both discrimination and calibration. However, the Brier score is prevalence dependent in such a way that the rank ordering of tests or models may inappropriately vary by prevalence.},
	number = {1},
	urldate = {2020-12-17},
	journal = {Diagnostic and Prognostic Research},
	author = {Assel, Melissa and Sjoberg, Daniel D. and Vickers, Andrew J.},
	month = dec,
	year = {2017},
	keywords = {Brier score, Concordance index, Mean squared error, Net benefit, Prediction modeling, Sensitivity, Specificity},
	pages = {19},
	file = {Full Text PDF:files/2508/Assel et al. - 2017 - The Brier score does not evaluate the clinical uti.pdf:application/pdf;Snapshot:files/2509/s41512-017-0020-3.html:text/html}
}

@article{blanche_c-index_2019,
	title = {The c-index is not proper for the evaluation of \$t\$-year predicted risks},
	volume = {20},
	issn = {1465-4644},
	url = {https://doi.org/10.1093/biostatistics/kxy006},
	doi = {10.1093/biostatistics/kxy006},
	abstract = {We show that the widely used concordance index for time to event outcome is not proper when interest is in predicting a \$t\$-year risk of an event, for example 10-year mortality. In the situation with a fixed prediction horizon, the concordance index can be higher for a misspecified model than for a correctly specified model. Impropriety happens because the concordance index assesses the order of the event times and not the order of the event status at the prediction horizon. The time-dependent area under the receiver operating characteristic curve does not have this problem and is proper in this context.},
	number = {2},
	urldate = {2020-12-17},
	journal = {Biostatistics},
	author = {Blanche, Paul and Kattan, Michael W and Gerds, Thomas A},
	month = apr,
	year = {2019},
	pages = {347--357},
	file = {Full Text PDF:files/2512/Blanche et al. - 2019 - The c-index is not proper for the evaluation of \$t.pdf:application/pdf}
}

@article{hand_measuring_2009,
	title = {Measuring classifier performance: a coherent alternative to the area under the {ROC} curve},
	volume = {77},
	shorttitle = {Measuring classifier performance},
	number = {1},
	journal = {Machine learning},
	author = {Hand, David J.},
	year = {2009},
	note = {Publisher: Springer},
	pages = {103--123},
	file = {Full Text:files/2517/Hand - 2009 - Measuring classifier performance a coherent alter.pdf:application/pdf}
}

@inproceedings{khosla_integrated_2010,
	title = {An integrated machine learning approach to stroke prediction},
	booktitle = {Proceedings of the 16th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining},
	author = {Khosla, Aditya and Cao, Yu and Lin, Cliff Chiung-Yu and Chiu, Hsu-Kuang and Hu, Junling and Lee, Honglak},
	year = {2010},
	pages = {183--192},
	file = {Full Text:files/2519/Khosla et al. - 2010 - An integrated machine learning approach to stroke .pdf:application/pdf;Snapshot:files/2520/1835804.html:text/html}
}
