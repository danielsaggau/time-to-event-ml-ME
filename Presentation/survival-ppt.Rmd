---
title: "Model Evaluation"
author: "Daniel Saggau"
date: "11/15/2020"
output:
  beamer_presentation: default
  slidy_presentation: default
  powerpoint_presentation: default
  ioslides_presentation: default
subtitle: Considerations for Time-to-Event Studies
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Overview

* Time to Event Studies: 

*What is a time to event study ?*

* Classical Model Evaluation: 

*Why cant we use them?*

* TTS Model Evaluation: 

*How do we derive these methods (c-index, ibs)?*

* Discussion :

*What are the shortcomings of these methods?*

* Further Considerations: 

*What solutions exist?* 

## Time-to Event Studies 

- Analysis working with (right) censored data
- Highly relevant for clinicians in the field of medical statistics e.g. looking at when a patient dies or when he gets a disease (clinical/epidemiological studies)
- In Economics/Finance e.g. to examine when a subject/borrower will default or when a subject will find/lose a job 
- Operations research to predict the time a machine will break 

## Basic Notations & Concepts

* Time T and Survival S
* From hazard to cumulative hazard to survival 
* Hazard h(t,x) is the eminent probability of death a specific point in time 
* Capital H is the cumulative hazard
* non-parametric hazard models (KM) vs.semi-parametric proportional hazard model

## Model Evaluation - Considerations

(1) *What type of study are we dealing with?*

**Diagnostic vs. Prognostic Study**

(2) *What are the components of our model evaluation metric?*

**Discrimination**: Are we able to correctly discriminate between e.g. sick and healthy patients ?
**Calibration**: How concise is our prediction accuracy ?
**Clinical Usefulness**: Will our model create more benefits than harm? 

## Classical Model Evaluation Tools for Classification Tasks

Working with *Label* vs. working with *Probability*

* Brier Score (probability from true class label)
* 
* AUC/ROC (receiver operating characteristics)
* Mis-classification Error rate (rate of incorrect classification)
* ACC (rate of correct classifications)
* Concordance Statistics

## Brier Score 

* Based on loss function 

MSE for Regression (L2 Loss):

$BS= \frac{1}{n}\sum^n_{i=1}(y^{(i)})-\hat{y}^{(i)})^2$

Where: the $MSE \in [0;\infty)$

The Brier Score is the MSE for Classification: 

$BS= \frac{1}{n}\sum^n_{i=1}(\hat{\pi}(x^{(i)})-y^{(i)})^2$

The general version of the brier score looks at a specific point in time

## Confusion Matrix

**Sensitivity**:

* deals with values above the threshold among the subject group which do endure an event 
* Another common name for Sensitivity is the true positive rate.

$TPF = \frac{TP}{TP+FN}$

**Specificity**:

* deals with false negatives, hence patients with a disease we classify as not having any diseases
* Another name for specificity is the true negative rate 

$TNR = \frac{TN}{TN+FP}$

## Why cant we use traditional model evaluation tools for time to event studies?

* Working with censored data
``
* Right censored data (event after follow up) vs. left censored data (event was not recorded when it occured intially)
* We need to estimate survival of patients without having data on e.g. death
* Also, we need to provide measure over time

Early approaches:
 - excluding subjects with right censored data and only evaluate on the complete data

## From ROC to C-Statistic to C-index

- Advancement of ROC/AUC
- Further modification leads to c-index
- concordance pairs divided
- concordance == $x1>x2-> y1>y2$
- Harell's C

## c-index 

* studying concordance pairs of subjects
* addressing right censored data via inverse of the probability of censoring weighted estimate (of concordance probability)
* kendall's tau as conservative weight 
* Summary measure (over all time) based on the AUC  

$C-index = \frac{\Delta_j \times \sum_{i,j}1_{Ti>Tj} \times 1_{\eta_i>\eta_j}} {\Delta_j \times \sum_{i,j}1_{Ti>Tj}}$

* Where 1 are indicator-functions: 



```{r}
library(prodlim)
library(survival)
library(randomForestSRC)
 set.seed(13)
 dat <- SimSurv(500)
 # fit three different Cox models and a random survival forest
 cox12 <- coxph(Surv(time,status)~X1+X2,data=dat,x=TRUE,y=TRUE)
 cox1 <- coxph(Surv(time,status)~X1,data=dat,x=TRUE,y=TRUE)
 cox2 <- coxph(Surv(time,status)~X2,data=dat,x=TRUE,y=TRUE)
 rsf1 <- rfsrc(Surv(time,status)~X1+X2,data=dat,ntree=15,forest=TRUE)

A1  <- pec::cindex(list("Cox X1"=cox1, "RSF"=rsf1),
formula=Surv(time,status)~X1+X2,
data=dat,
eval.times=10)
ApparrentCindex  <- pec::cindex(list("Cox X1"=cox1,
"Cox X2"=cox2,
"Cox X1+X2"=cox12,
"RSF"=rsf1),
formula=Surv(time,status)~X1+X2,
data=dat,
eval.times=seq(1,15,1))
  print(ApparrentCindex)
  plot(ApparrentCindex)
```

## IBS

* called cumulative predictive error curves == continuous ranked probability score (crps)
* area under the prediction error curve
* Integral over all points in time to get one summary value henceforth called "integrated" BS
* able to build a R^2 like measure where we divide MSE of a model with a different MSE of reference model 
* Where L is a loss function of the S(the probability that the event of interest has not taken place yet) and time
* t is the time of the event (death) and t* the time before death
* G(t) is the P(C>t), so where the censored time is longer than the time (in mlr3proba via survfit == KM Estimate)
* When selecting integrated == FALSE then we looking at specific time 

## For the population mean:

$$
L(S,t|t^*) = \frac{1}{N}\displaystyle\sum^N_{i=1}L(S_i,t_i|t^*) \tag{9}
$$

### Mean Population: 

$$L(S,t|t^*) = \frac{1}{NT}\displaystyle\sum^N_{i=1}\displaystyle\sum ^T_{j=1}L(S_i,t_i|t^*)$$

* N = Number of observations 
* S_i is the predicted survival function 

## Calibration Plot

```{r, include =F}
set.seed(123)
library(prodlim)
library(survival)
library(pec)
dat=SimSurv(1000)
models <- list("Cox.X1"=coxph(Surv(time,status)~X1,data=dat,x=TRUE,y=TRUE),
               "Cox.X2"=coxph(Surv(time,status)~X2,data=dat,x=TRUE,y=TRUE),
               "Cox.X1.X2"=coxph(Surv(time,status)~X1+X2,data=dat,x=TRUE,y=TRUE))
perror <- pec(object=models,
                 formula=Surv(time,status)~1, data=dat, # formula for IPCW
                 exact=TRUE, cens.model="cox", splitMethod="none",  #Method for estimating inverse probability of censoring weigth
                 B=0,# number boostrap samples 
                 verbose=TRUE)
y<- ibs(perror,times=1)
```

```{r}
calPlot(models)
```

## Summary Prediction Error Curves

```{r}
summary(perror,times=seq(0,20,5))
```

## Plotting prediction error

```{r}
plot(perror,xlim=c(0,25), ylim = c(0,1))
```

## Cumulative Prediction Error 

```{r}
crps(perror,times=seq(0,20,5))
crps(perror)
```

## c-index plot

```{r}
cindex <- cindex(models,formula = Surv(time,status) ~ 1, cens.model="marginal", data = dat,eval.times = seq(1,23.4,1))
plot(cindex)
```

## mlr3Proba 

* van Houwelingen’s Alpha Calibration 
* van Houwelingen’s Beta Calibration
* Integrated Graf Score (other Name for IBS based on Author Graf)
* Integrated Log Loss
* Log Loss

Further measures via survAUC package:

* Uno's AUC/TPR/TNR
* Song and Zhou’s AUC/TNR/TPR
* Chambless and Diao’s AUC
* Hung and Chiang’s AUC

## mlr3Proba Example

```{r, include =F}
library("mlr3learners")
library("mlr3")
library("mlr3proba")
library("survival")
library("ranger")
library("mlr3viz")
library("survAUC")

TaskSurv$new(id = "interval_censored", backend = survival::bladder2[,-c(1, 7)],
             time = "start", time2 = "stop", type = "interval2")
task = tsk("rats")
# some integrated learners
learners = lrns(c("surv.coxph", "surv.kaplan", "surv.ranger"))
# print(learners)

# Harrell's C-Index for survival
measure = msr("surv.graf")
print(measure)

set.seed(1)
bmr = benchmark(benchmark_grid(task, learners, rsmp("cv", folds = 3)))
bmr$aggregate(measure)
```

```{r}
autoplot(bmr, measure = measure)
```


## Discussion 

* Integrated Brier Score accounts for both calibration and discrimination
* Irrespective, neither model accounts and leaves room for improvement 

## Literature and Recommendations 

Introduction:

* Steyerberg, E. W., Vickers, A. J., Cook, N. R., Gerds, T., Gonen, M., Obuchowski, N., ... & Kattan, M. W. (2010). Assessing the performance of prediction models: a framework for some traditional and novel measures. Epidemiology (Cambridge, Mass.), 21(1), 128.

Comparative Study:

* Kattan, M. W., & Gerds, T. A. (2018). The index of prediction accuracy: an intuitive measure useful for evaluating risk prediction models. Diagnostic and prognostic research, 2(1), 7.

Use Cases:

https://rpubs.com/kaz_yos/survival-auc
https://datascienceplus.com/time-dependent-roc-for-survival-prediction-models-in-r/
https://rdrr.io/cran/pec/
https://adibender.github.io/pammtools/
